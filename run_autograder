#!/usr/bin/python3.8

# =================================================================
#                   Question object creation
# =================================================================
# # Example of potential procedural question creation
#
# for i in range(1,4):
#     for j in range(1,6):
#         qid = f'{i}-{j}'
#         main_compile = CompileTest(points=1, provided_files = [],
#                                    submitted_files=[f'main-{i}-{j}.cpp', f'function-{i}-{j}.cpp'])
#         test_compile = CompileTest(points=1, provided_files = [f'test-{i}-{j}.cpp'],
#                                    submitted_files=[f'function-{i}-{j}.cpp'])
#         questions.append(Question(question_id=qid, max_points=5, file_points=1, test_points=1,
#                                   compile_tests=[main_compile,test_compile], tester_idx=1))
#
# questions.append(Question("FileTest", max_points=1, file_points=1, extra_files=["plan.txt", "solution-1-1.txt"]))

# import os

# if os.path.exists("autograder_util.py") == False:
#     print("Required file autograder_util.py not found. Downloading...")
#     from urllib.request import urlopen

#     url = "https://raw.githubusercontent.com/rhys-brailsford/gs_autograder/main/autograder_util.py"

#     response = urlopen(url)
#     with open("autograder_util.py", "w") as f: f.write(response.read().decode())

import json
import autograder_util as ag


# ========================================================================
#              Set to true if assignment is a workshop.
# If true, overwrites final score to participation_grade regardless of tests
# for participation grade.
participation_only = False
participation_grade = 1
# ========================================================================

# List of questions objects
questions = []

# 1-1
c_tests = []
# Test that submitted main file compiles with submitted function file
c_tests.append(ag.CompileTest(points=1, provided_files=[], submitted_files=["function-1-1.cpp", "main-1-1.cpp"]))
# Test that function compiles with test driver
c_tests.append(ag.CompileTest(points=1, provided_files=["test-1-1.cpp"], submitted_files=["function-1-1.cpp"]))
# Max points = 5 because there are 2tests + files + 2compiles (1pt each)
q = ag.Question("1-1", max_points=5, file_points=1, test_points=1, compile_tests=c_tests, tester_idx=1)
questions.append(q)

# 1-2
c_tests = []
# Test that submitted main file compiles with submitted function file
c_tests.append(ag.CompileTest(points=1, provided_files=[], submitted_files=["function-1-2.cpp", "main-1-2.cpp"]))
# Test that function compiles with test driver
c_tests.append(ag.CompileTest(points=1, provided_files=["test-1-2.cpp"], submitted_files=["function-1-2.cpp"]))
# Max points = 6 because there are 3tests + files + 2compiles (1pt each)
q = ag.Question("1-2", max_points=6, file_points=1, test_points=1, compile_tests=c_tests, tester_idx=1)
questions.append(q)


# 2-1
c_tests = []
# Test that submitted main file compiles with submitted function file
c_tests.append(ag.CompileTest(points=1, provided_files=[], submitted_files=["function-2-1.cpp", "main-2-1.cpp"]))
# Test that function compiles with test driver
c_tests.append(ag.CompileTest(points=1, provided_files=["test-2-1.cpp"], submitted_files=["function-2-1.cpp"]))
# Max points = 5 because there are 2tests + files + 2compiles (1pt each)
q = ag.Question("2-1", max_points=5, file_points=1, test_points=1, compile_tests=c_tests, tester_idx=1)
questions.append(q)

# 3-1
c_tests = []
# Test that submitted main file compiles with submitted function file
# Test that function compiles with test driver
c_tests.append(ag.CompileTest(points=1, provided_files=["test-3-1.cpp"], submitted_files=["SingleClass.cpp"]))
# Max points = 5 because there are 2tests + files + 2compiles (1pt each)
q = ag.Question("3-1", max_points=3, file_points=1, test_points=1, compile_tests=c_tests, tester_idx=(len(c_tests)-1), extra_files=["SingleClass.h"])
questions.append(q)

# 3-2
c_tests = []
# Test that submitted main file compiles with submitted function file
# Test that function compiles with test driver
c_tests.append(ag.CompileTest(points=1, provided_files=["test-3-2.cpp"], submitted_files=["SingleClass.cpp", "AggClass.cpp"]))
# Max points = 5 because there are 2tests + files + 2compiles (1pt each)
q = ag.Question("3-2", max_points=3, file_points=1, test_points=1, compile_tests=c_tests, tester_idx=(len(c_tests)-1), extra_files=["AggClass.h"])
questions.append(q)



result_json = ag.run_questions(questions, participation_only, participation_grade)

# close Gradescope results file
with open('results/results.json', 'w') as file:
    json.dump(result_json, file)

final_score = -1
try:
    final_score = result_json["score"]
except:
    print("result_json key error: Missing score key.")
    print(result_json)
print(f'Final grade:{final_score}')
